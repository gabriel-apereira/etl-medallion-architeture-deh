# ğŸ Medallion Architecture â€” ETL em Python (Local + AWS)

Este projeto foi desenvolvido como parte do curso do **[Data Engineer Help]**

Este projeto demonstra como implementar a **Arquitetura Medallion**  de duas formas:  
- **Local:** execuÃ§Ã£o e testes na mÃ¡quina do desenvolvedor com Python, utilizando scripts em python e armazenamento final no SQL Server local.  
- **AWS:** implantaÃ§Ã£o em serviÃ§os gerenciados para escalabilidade e anÃ¡lise avanÃ§ada.  

A arquitetura Ã© dividida em trÃªs camadas (Bronze, Silver e Gold), utilizando **S3, Glue, Athena e Redshift** para criar um pipeline robusto de ingestÃ£o, transformaÃ§Ã£o e anÃ¡lise de dados.

---

## ğŸ¯ Objetivos
- Armazenar dados brutos (CSV, JSON) de forma segura e escalÃ¡vel  
- Validar e transformar os dados para formatos otimizados (Parquet)  
- Enriquecer os dados para anÃ¡lises e dashboards  
- Utilizar serviÃ§os gerenciados da AWS para orquestraÃ§Ã£o e consulta  
- Fornecer um ambiente acessÃ­vel para anÃ¡lise exploratÃ³ria e visualizaÃ§Ã£o  

---

## ğŸ› ï¸ Tecnologias Utilizadas
- **Python**  
- **SQL**  
- **AWS S3, Glue, Athena, Redshift, QuickSight**

---

## ğŸ“‚ Estrutura do Projeto
```
medallion-architecture/
â”‚
â”œâ”€â”€ data/                      # Dados organizados por camadas
â”‚   â”œâ”€â”€ bronze/                # Camada Bronze: dados brutos
â”‚   â”‚   â”œâ”€â”€ cep_info.csv
â”‚   â”‚   â”œâ”€â”€ products.json
â”‚   â”‚   â””â”€â”€ users.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ silver/                # Camada Silver: dados tratados/validados
â”‚   â”‚   â”œâ”€â”€ cep_info.parquet
â”‚   â”‚   â”œâ”€â”€ products.parquet
â”‚   â”‚   â””â”€â”€ users.parquet
â”‚   â”‚
â”‚   â””â”€â”€ gold/                  # Camada Gold: dados prontos para anÃ¡lise
â”‚       â””â”€â”€ query.sql
â”‚
â”œâ”€â”€ etl/                       # Scripts de ETL (local)
â”‚   â”œâ”€â”€ extract/               # ExtraÃ§Ã£o
â”‚   â”‚   â””â”€â”€ get_data.py
â”‚   â”‚
â”‚   â”œâ”€â”€ transform/             # TransformaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ normalize_data.py
â”‚   â”‚   â””â”€â”€ normalize_data_class.py
â”‚   â”‚
â”‚   â”œâ”€â”€ load/                  # Carregamento
â”‚   â”‚   â””â”€â”€ populate_db.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                 # UtilitÃ¡rios
â”‚   â”‚   â”œâ”€â”€ db.py              # ConexÃ£o com banco
â”‚   â”‚   â”œâ”€â”€ data-view.py       # VisualizaÃ§Ã£o dos dados
â”‚   â”‚   â””â”€â”€ teste_conexao.py   # Teste de conexÃ£o
â”‚
â””â”€â”€ docs/                      # DocumentaÃ§Ã£o e diagramas
    â””â”€â”€ architecture-diagram.png
```

## â˜ï¸ Guia RÃ¡pido na AWS
- **Bronze**: : Armazene os dados brutos em buckets S3 
- **Silver**: Use AWS Glue para validar e transformar os dados (Parquet)
- **Gold**: FaÃ§a queries com Athena diretamente nos dados prontos no S3
- **Data Access**: Importe os dados no Amazon Redshift e conecte ao Amazon QuickSight para dashboards

## ğŸ“¸ Diagrama

<img width="1194" height="1572" alt="architecture-diagram" src="https://github.com/user-attachments/assets/2be4cbbb-8519-48e9-b4f3-91f8580d9815" />

